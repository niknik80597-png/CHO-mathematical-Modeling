
"""
–ì–∏–±—Ä–∏–¥–Ω—ã–π —Å–∏–º—É–ª—è—Ç–æ—Ä: –º–µ—Ö–∞–Ω–∏—Å—Ç–∏—á–µ—Å–∫–∞—è –º–æ–¥–µ–ª—å + ML –∫–æ—Ä—Ä–µ–∫—Ü–∏—è
"""

import numpy as np
import pandas as pd
import pickle
import os
import json
from datetime import datetime
import glob

# –ò–º–ø–æ—Ä—Ç–∏—Ä—É–µ–º –º–µ—Ö–∞–Ω–∏—Å—Ç–∏—á–µ—Å–∫—É—é –º–æ–¥–µ–ª—å
from main_simulation import run_simulation, create_comparison_df
from model.simulator import simulation_step


class HybridSimulator:
    """–ì–∏–±—Ä–∏–¥–Ω—ã–π —Å–∏–º—É–ª—è—Ç–æ—Ä —Å ML –∫–æ—Ä—Ä–µ–∫—Ü–∏–µ–π"""

    def __init__(self, use_ml_correction=True):
        self.use_ml_correction = use_ml_correction
        self.ml_model = None
        self.scaler = None
        self.feature_names = None

        if use_ml_correction:
            self.load_ml_model()

    def load_ml_model(self):
        """–ó–∞–≥—Ä—É–∑–∫–∞ –æ–±—É—á–µ–Ω–Ω–æ–π ML –º–æ–¥–µ–ª–∏"""
        try:
            model_path = "ml_models/random_forest_model.pkl"
            scaler_path = "ml_models/scaler.pkl"

            if not os.path.exists(model_path):
                print("‚ö†Ô∏è  ML –º–æ–¥–µ–ª—å –Ω–µ –Ω–∞–π–¥–µ–Ω–∞! –ë—É–¥–µ—Ç –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å—Å—è —Ç–æ–ª—å–∫–æ –º–µ—Ö–∞–Ω–∏—Å—Ç–∏—á–µ—Å–∫–∞—è –º–æ–¥–µ–ª—å")
                self.use_ml_correction = False
                return

            with open(model_path, "rb") as f:
                self.ml_model = pickle.load(f)

            with open(scaler_path, "rb") as f:
                self.scaler = pickle.load(f)

            # –ó–∞–≥—Ä—É–∂–∞–µ–º –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ –ø—Ä–∏–∑–Ω–∞–∫–∞—Ö
            info_path = "ml_models/model_info.json"
            if os.path.exists(info_path):
                with open(info_path, "r") as f:
                    model_info = json.load(f)
                self.feature_names = model_info.get('features_used', [])

            print(f"‚úÖ ML –º–æ–¥–µ–ª—å –∑–∞–≥—Ä—É–∂–µ–Ω–∞: {self.ml_model.__class__.__name__}")
            print(f"   –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –¥–µ—Ä–µ–≤—å–µ–≤: {self.ml_model.n_estimators}")

        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –∑–∞–≥—Ä—É–∑–∫–µ ML –º–æ–¥–µ–ª–∏: {str(e)}")
            self.use_ml_correction = False

    def prepare_features_for_prediction(self, state, rates, t, t_shift, params):
        """
        –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ –¥–ª—è ML –º–æ–¥–µ–ª–∏
        """
        features = {}

        # 1. –û—Å–Ω–æ–≤–Ω—ã–µ —Å–æ—Å—Ç–æ—è–Ω–∏—è
        features['time_h'] = t
        features['TCD'] = state.get('TCD', 0)
        features['glucose'] = state.get('G', 0)
        features['lactate'] = state.get('Lac', 0)
        features['ammonium'] = state.get('NH4', 0)
        features['model_titer'] = state.get('P', 0)

        # 2. –ü—Ä–æ–∏–∑–≤–æ–¥–Ω—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏
        features['time_norm'] = t / 240 if t > 0 else 0  # –ù–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è –ø–æ –æ–±—â–µ–º—É –≤—Ä–µ–º–µ–Ω–∏
        features['glucose_lactate_ratio'] = features['glucose'] / (features['lactate'] + 0.1)
        features['metabolic_quotient'] = features['lactate'] / (features['glucose'] + 0.1)

        # 3. –ö–∏–Ω–µ—Ç–∏—á–µ—Å–∫–∏–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã
        features['mu'] = rates.get('mu', 0)
        features['qP'] = rates.get('qP', 0)
        features['qG'] = rates.get('qG', 0)

        # 4. –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏
        features['TCD_squared'] = features['TCD'] ** 2
        features['glucose_squared'] = features['glucose'] ** 2
        features['TCD_times_time'] = features['TCD'] * features['time_norm']

        # 5. –¢–µ–º–ø–µ—Ä–∞—Ç—É—Ä–Ω–∞—è —Ñ–∞–∑–∞
        features['temperature_phase'] = 0 if t < t_shift else 1

        # 6. –í—Ä–µ–º—è –ø–æ—Å–ª–µ —Å–¥–≤–∏–≥–∞
        features['time_post_shift'] = max(0, t - t_shift)

        return features

    def get_ml_correction(self, features_dict):
        """
        –ü–æ–ª—É—á–µ–Ω–∏–µ ML –∫–æ—Ä—Ä–µ–∫—Ü–∏–∏ –¥–ª—è –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è
        """
        if not self.use_ml_correction or self.ml_model is None:
            return 0.0

        try:
            # –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º —Å–ª–æ–≤–∞—Ä—å –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ –≤ –º–∞—Å—Å–∏–≤
            if self.feature_names:
                # –ò—Å–ø–æ–ª—å–∑—É–µ–º —Ç–æ–ª—å–∫–æ —Ç–µ –ø—Ä–∏–∑–Ω–∞–∫–∏, –∫–æ—Ç–æ—Ä—ã–µ –±—ã–ª–∏ –ø—Ä–∏ –æ–±—É—á–µ–Ω–∏–∏
                features_array = []
                for feature_name in self.feature_names:
                    if feature_name in features_dict:
                        features_array.append(features_dict[feature_name])
                    else:
                        features_array.append(0.0)  # –ó–∞–ø–æ–ª–Ω—è–µ–º –Ω—É–ª—è–º–∏ –æ—Ç—Å—É—Ç—Å—Ç–≤—É—é—â–∏–µ –ø—Ä–∏–∑–Ω–∞–∫–∏
            else:
                # –ï—Å–ª–∏ –Ω–µ—Ç –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –æ –ø—Ä–∏–∑–Ω–∞–∫–∞—Ö, –∏—Å–ø–æ–ª—å–∑—É–µ–º –≤—Å–µ
                features_array = list(features_dict.values())

            # –ú–∞—Å—à—Ç–∞–±–∏—Ä–æ–≤–∞–Ω–∏–µ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤
            if self.scaler:
                features_scaled = self.scaler.transform([features_array])
            else:
                features_scaled = [features_array]

            # –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ –∫–æ—Ä—Ä–µ–∫—Ü–∏–∏
            correction = self.ml_model.predict(features_scaled)[0]

            # –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º –∫–æ—Ä—Ä–µ–∫—Ü–∏—é —Ä–∞–∑—É–º–Ω—ã–º–∏ –ø—Ä–µ–¥–µ–ª–∞–º–∏
            max_correction = 0.5  # –ú–∞–∫—Å–∏–º–∞–ª—å–Ω–∞—è –∫–æ—Ä—Ä–µ–∫—Ü–∏—è 50%
            correction = np.clip(correction, -max_correction, max_correction)

            return correction

        except Exception as e:
            print(f"‚ö†Ô∏è  –û—à–∏–±–∫–∞ –ø—Ä–∏ –ø–æ–ª—É—á–µ–Ω–∏–∏ ML –∫–æ—Ä—Ä–µ–∫—Ü–∏–∏: {str(e)}")
            return 0.0

    def hybrid_simulation_step(self, state, inputs, params, dt, t_shift, temp_coeffs, batch_id=None):
        """
        –ì–∏–±—Ä–∏–¥–Ω—ã–π —à–∞–≥ —Å–∏–º—É–ª—è—Ü–∏–∏: –º–µ—Ö–∞–Ω–∏—Å—Ç–∏–∫–∞ + ML –∫–æ—Ä—Ä–µ–∫—Ü–∏—è
        """
        # –ú–µ—Ö–∞–Ω–∏—Å—Ç–∏—á–µ—Å–∫–∏–π —à–∞–≥
        new_state, rates = simulation_step(state, inputs, params, dt, t_shift, temp_coeffs)

        # –ï—Å–ª–∏ –≤–∫–ª—é—á–µ–Ω–∞ ML –∫–æ—Ä—Ä–µ–∫—Ü–∏—è –∏ –µ—Å—Ç—å –¥–∞–Ω–Ω—ã–µ –æ —Ç–∏—Ç—Ä–µ
        if self.use_ml_correction and 'P' in new_state:
            # –ü–æ–¥–≥–æ—Ç–∞–≤–ª–∏–≤–∞–µ–º –ø—Ä–∏–∑–Ω–∞–∫–∏ –¥–ª—è ML
            features = self.prepare_features_for_prediction(
                new_state, rates, state['time_h'], t_shift, params
            )

            # –ü–æ–ª—É—á–∞–µ–º ML –∫–æ—Ä—Ä–µ–∫—Ü–∏—é –¥–ª—è —Ç–∏—Ç—Ä–∞
            ml_correction = self.get_ml_correction(features)

            # –ü—Ä–∏–º–µ–Ω—è–µ–º –∫–æ—Ä—Ä–µ–∫—Ü–∏—é –∫ —Ç–∏—Ç—Ä—É
            original_titer = new_state['P']
            corrected_titer = original_titer * (1 + ml_correction)

            # –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º —Ç–∏—Ç—Ä —Å–Ω–∏–∑—É –Ω—É–ª–µ–º
            new_state['P'] = max(corrected_titer, 0.0)

            # –°–æ—Ö—Ä–∞–Ω—è–µ–º –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ –∫–æ—Ä—Ä–µ–∫—Ü–∏–∏ –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞
            new_state['ml_correction'] = ml_correction
            new_state['ml_correction_abs'] = corrected_titer - original_titer

        return new_state, rates


def run_hybrid_simulation(csv_path=None, meta_path=None, output_path=None,
                          batch_id=None, use_ml_correction=True):
    """
    –ó–∞–ø—É—Å–∫ –≥–∏–±—Ä–∏–¥–Ω–æ–π —Å–∏–º—É–ª—è—Ü–∏–∏ –¥–ª—è –æ–¥–Ω–æ–π –ø–∞—Ä—Ç–∏–∏
    """
    print(f"\nü§ñ –ó–ê–ü–£–°–ö –ì–ò–ë–†–ò–î–ù–û–ô –°–ò–ú–£–õ–Ø–¶–ò–ò: {batch_id}")

    # –ó–∞–≥—Ä—É–∂–∞–µ–º —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç–∞–ª—å–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ
    df_exp = pd.read_csv(csv_path)

    # –°–æ–∑–¥–∞–µ–º –≥–∏–±—Ä–∏–¥–Ω—ã–π —Å–∏–º—É–ª—è—Ç–æ—Ä
    simulator = HybridSimulator(use_ml_correction=use_ml_correction)

    # –ó–∞–≥—Ä—É–∂–∞–µ–º –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –∏–∑ JSON
    with open(meta_path, 'r') as f:
        meta = json.load(f)

    # –ù–∞—á–∞–ª—å–Ω—ã–µ —É—Å–ª–æ–≤–∏—è
    initial = meta["initial_conditions"]
    state = {
        "time_h": 0,
        "V": initial["V"],
        "TCD": initial["TCD"],
        "Xv": initial["TCD"] * initial["Viab"],
        "G": initial["G"],
        "Lac": initial["Lac"],
        "NH4": initial["NH4"],
        "P": initial["P"],
        "viability": initial["Viab"]
    }

    params = meta["kinetics_parameters"]
    t_shift = meta["process_parameters"]["time_shift_h"]
    dt = meta.get("time_step_h", meta["process_time"]["time_step_h"])
    total_duration = meta["process_time"]["total_duration_h"]
    temp_coeffs = meta["temperature_coefficients"]

    # –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –∏–Ω—Ç–µ—Ä–ø–æ–ª—è—Ç–æ—Ä–æ–≤ –¥–ª—è –ø–æ–¥–∞—á–∏
    time_points = df_exp['time_h'].values

    from scipy.interpolate import interp1d
    feed_glucose_interp = interp1d(
        time_points, df_exp['feed_glucose_gph'].values,
        bounds_error=False, fill_value=0.0
    )
    feed_other_interp = interp1d(
        time_points, df_exp['feed_other_gph'].values,
        bounds_error=False, fill_value=0.0
    )

    # –¶–∏–∫–ª –≥–∏–±—Ä–∏–¥–Ω–æ–π —Å–∏–º—É–ª—è—Ü–∏–∏
    results = []
    rates_history = []
    ml_corrections = []

    simulation_times = np.arange(0, total_duration + dt, dt)

    for i, t in enumerate(simulation_times):
        # –ü–æ–ª—É—á–∞–µ–º –≤—Ö–æ–¥–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ
        F_glc = float(feed_glucose_interp(t))
        F_other = float(feed_other_interp(t))

        # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ç–µ–∫—É—â–µ–µ —Å–æ—Å—Ç–æ—è–Ω–∏–µ
        results.append(state.copy())

        # –í—ã–ø–æ–ª–Ω—è–µ–º –≥–∏–±—Ä–∏–¥–Ω—ã–π —à–∞–≥
        state, rates = simulator.hybrid_simulation_step(
            state=state,
            inputs=(F_glc, F_other),
            params=params,
            dt=dt,
            t_shift=t_shift,
            temp_coeffs=temp_coeffs,
            batch_id=batch_id
        )

        # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Å–∫–æ—Ä–æ—Å—Ç–∏ –∏ ML –∫–æ—Ä—Ä–µ–∫—Ü–∏–∏
        rates["time_h"] = t
        rates_history.append(rates)

        if 'ml_correction' in state:
            ml_corrections.append({
                'time_h': t,
                'correction': state['ml_correction'],
                'correction_abs': state.get('ml_correction_abs', 0),
                'original_titer': state.get('P', 0) / (1 + state['ml_correction'])
                if state['ml_correction'] != 0 else state.get('P', 0)
            })

        # –ü—Ä–æ–≥—Ä–µ—Å—Å
        if i % 10 == 0:
            progress = t / total_duration * 100
            print(f"  –ü—Ä–æ–≥—Ä–µ—Å—Å: {progress:.1f}% (t={t:.0f} —á, P={state['P']:.2f} –≥/–ª)")

    # –°–æ–∑–¥–∞–µ–º DataFrames
    results_df = pd.DataFrame(results)
    rates_df = pd.DataFrame(rates_history)

    if ml_corrections:
        ml_df = pd.DataFrame(ml_corrections)
    else:
        ml_df = pd.DataFrame()

    results_df["NH4_mM"] = results_df["NH4"] / 0.018
    results_df["batch_id"] = batch_id

    # –°—Ä–∞–≤–Ω–µ–Ω–∏–µ —Å —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç–∞–ª—å–Ω—ã–º–∏ –¥–∞–Ω–Ω—ã–º–∏
    comparison_df = create_comparison_df(results_df, df_exp, batch_id)

    # –î–æ–±–∞–≤–ª—è–µ–º –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ ML –∫–æ—Ä—Ä–µ–∫—Ü–∏–∏ –≤ comparison_df
    if not ml_df.empty:
        # –ò–Ω—Ç–µ—Ä–ø–æ–ª–∏—Ä—É–µ–º –∫–æ—Ä—Ä–µ–∫—Ü–∏–∏ –Ω–∞ –≤—Ä–µ–º–µ–Ω–∞ —Å—Ä–∞–≤–Ω–µ–Ω–∏—è
        from scipy.interpolate import interp1d
        ml_interp = interp1d(ml_df['time_h'], ml_df['correction'],
                             bounds_error=False, fill_value=0.0)
        comparison_df['ml_correction'] = ml_interp(comparison_df['time_h'])

        ml_abs_interp = interp1d(ml_df['time_h'], ml_df['correction_abs'],
                                 bounds_error=False, fill_value=0.0)
        comparison_df['ml_correction_abs'] = ml_abs_interp(comparison_df['time_h'])

    # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
    if output_path:
        os.makedirs(os.path.dirname(output_path), exist_ok=True)

        base_name = f"{output_path}_{batch_id}_hybrid"
        results_df.to_csv(f"{base_name}_states.csv", index=False)
        rates_df.to_csv(f"{base_name}_rates.csv", index=False)
        comparison_df.to_csv(f"{base_name}_comparison.csv", index=False)

        if not ml_df.empty:
            ml_df.to_csv(f"{base_name}_ml_corrections.csv", index=False)

        print(f"‚úÖ –†–µ–∑—É–ª—å—Ç–∞—Ç—ã —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã: {base_name}_*.csv")

    print(f"\nüéØ –ò–¢–û–ì–ò –ì–ò–ë–†–ò–î–ù–û–ô –°–ò–ú–£–õ–Ø–¶–ò–ò {batch_id}:")
    print(f"   - –ö–æ–Ω–µ—á–Ω—ã–π —Ç–∏—Ç—Ä: {results_df['P'].iloc[-1]:.2f} –≥/–ª")
    print(f"   - –ü–∏–∫–æ–≤–∞—è Xv: {results_df['Xv'].max():.2f} √ó10‚Å∂ –∫–ª/–º–ª")

    if not ml_df.empty:
        avg_correction = ml_df['correction'].mean() * 100
        print(f"   - –°—Ä–µ–¥–Ω—è—è ML –∫–æ—Ä—Ä–µ–∫—Ü–∏—è: {avg_correction:.1f}%")

    return {
        'results_df': results_df,
        'rates_df': rates_df,
        'comparison_df': comparison_df,
        'ml_corrections': ml_df,
        'batch_id': batch_id
    }


def run_all_hybrid_simulations(use_ml_correction=True):
    """
    –ó–∞–ø—É—Å–∫ –≥–∏–±—Ä–∏–¥–Ω–æ–π —Å–∏–º—É–ª—è—Ü–∏–∏ –¥–ª—è –≤—Å–µ—Ö –ø–∞—Ä—Ç–∏–π
    """
    print(f"\n{'=' * 80}")
    print(f"ü§ñ –ì–ò–ë–†–ò–î–ù–û–ï –ú–û–î–ï–õ–ò–†–û–í–ê–ù–ò–ï –í–°–ï–• –ü–ê–†–¢–ò–ô")
    print(f"{'=' * 80}")

    # –ù–∞—Ö–æ–¥–∏–º –≤—Å–µ –ø–∞—Ä—Ç–∏–∏
    data_dir = "data/raw"
    meta_dir = "data/meta"

    csv_files = glob.glob(os.path.join(data_dir, "batch_CHO*.csv"))
    all_results = {}

    for csv_path in csv_files:
        # –ò–∑–≤–ª–µ–∫–∞–µ–º –Ω–æ–º–µ—Ä –ø–∞—Ä—Ç–∏–∏
        base_name = os.path.basename(csv_path)
        batch_num = base_name.replace("batch_CHO", "").replace(".csv", "")
        batch_id = f"CHO{batch_num}"

        # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å—É—â–µ—Å—Ç–≤–æ–≤–∞–Ω–∏–µ JSON —Ñ–∞–π–ª–∞
        meta_path = os.path.join(meta_dir, f"batch_CHO{batch_num}.json")

        if not os.path.exists(meta_path):
            print(f"‚ö†Ô∏è  –ü—Ä–æ–ø—É—Å–∫–∞–µ–º {batch_id}: –Ω–µ—Ç JSON —Ñ–∞–π–ª–∞")
            continue

        print(f"\nüìä –ü–ê–†–¢–ò–Ø: {batch_id}")
        print(f"{'-' * 40}")

        try:
            # –ó–∞–ø—É—Å–∫–∞–µ–º –≥–∏–±—Ä–∏–¥–Ω—É—é —Å–∏–º—É–ª—è—Ü–∏—é
            output_prefix = f"data/hybrid_results/simulation_{batch_id}"

            results = run_hybrid_simulation(
                csv_path=csv_path,
                meta_path=meta_path,
                output_path=output_prefix,
                batch_id=batch_id,
                use_ml_correction=use_ml_correction
            )

            all_results[batch_id] = results

            print(f"‚úÖ {batch_id}: –£—Å–ø–µ—à–Ω–æ –∑–∞–≤–µ—Ä—à–µ–Ω–æ")

        except Exception as e:
            print(f"‚ùå {batch_id}: –û—à–∏–±–∫–∞ - {str(e)}")
            import traceback
            traceback.print_exc()

    # –í—ã—á–∏—Å–ª—è–µ–º –æ–±—â–∏–µ –º–µ—Ç—Ä–∏–∫–∏
    if all_results:
        metrics = calculate_hybrid_metrics(all_results)
        save_hybrid_results(all_results, metrics)

    print(f"\n{'=' * 80}")
    print(f"üéØ –ì–ò–ë–†–ò–î–ù–û–ï –ú–û–î–ï–õ–ò–†–û–í–ê–ù–ò–ï –ó–ê–í–ï–†–®–ï–ù–û")
    print(f"   –£—Å–ø–µ—à–Ω–æ: {len(all_results)} –ø–∞—Ä—Ç–∏–π")
    print(f"{'=' * 80}")

    return all_results


def calculate_hybrid_metrics(all_results):
    """
    –í—ã—á–∏—Å–ª–µ–Ω–∏–µ –º–µ—Ç—Ä–∏–∫ –¥–ª—è –≥–∏–±—Ä–∏–¥–Ω–æ–π –º–æ–¥–µ–ª–∏
    """
    from evaluation.metrics import calculate_calibration_metrics

    all_metrics = {}

    for batch_id, data in all_results.items():
        comparison_df = data['comparison_df']

        # –í—ã—á–∏—Å–ª—è–µ–º –º–µ—Ç—Ä–∏–∫–∏ (–±–µ–∑ –≥–ª—é–∫–æ–∑—ã)
        metrics = calculate_calibration_metrics(comparison_df, batch_id, exclude_glucose=True)
        all_metrics[batch_id] = metrics

    # –°–≤–æ–¥–Ω—ã–µ –º–µ—Ç—Ä–∏–∫–∏
    summary = {
        'total_batches': len(all_metrics),
        'batches': list(all_metrics.keys()),
        'mean_r2': np.mean([m['_summary']['Mean_R2'] for m in all_metrics.values()
                            if not np.isnan(m['_summary']['Mean_R2'])]),
        'mean_mape': np.mean([m['_summary']['Mean_MAPE'] for m in all_metrics.values()
                              if not np.isnan(m['_summary']['Mean_MAPE'])]),
        'timestamp': datetime.now().strftime("%Y-%m-%d %H:%M:%S")
    }

    return {
        'detailed': all_metrics,
        'summary': summary
    }


def save_hybrid_results(all_results, metrics):
    """
    –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –≥–∏–±—Ä–∏–¥–Ω–æ–≥–æ –º–æ–¥–µ–ª–∏—Ä–æ–≤–∞–Ω–∏—è
    """
    output_dir = "data/hybrid_results"
    os.makedirs(output_dir, exist_ok=True)

    # –°–æ—Ö—Ä–∞–Ω—è–µ–º –º–µ—Ç—Ä–∏–∫–∏ —Å –ø—Ä–∞–≤–∏–ª—å–Ω–æ–π –∫–æ–¥–∏—Ä–æ–≤–∫–æ–π
    metrics_path = os.path.join(output_dir, "hybrid_metrics.json")
    try:
        with open(metrics_path, "w", encoding='utf-8') as f:
            json.dump(metrics, f, indent=2, ensure_ascii=False)
        print(f"‚úÖ –ú–µ—Ç—Ä–∏–∫–∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã: {metrics_path}")
    except Exception as e:
        print(f"‚ö†Ô∏è  –û—à–∏–±–∫–∞ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è JSON: {str(e)}")
        # –ü—Ä–æ–±—É–µ–º —Å ensure_ascii=True –¥–ª—è ASCII-—Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç–∏
        with open(metrics_path, "w", encoding='utf-8') as f:
            json.dump(metrics, f, indent=2, ensure_ascii=True)
        print(f"‚úÖ –ú–µ—Ç—Ä–∏–∫–∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã —Å ASCII-–∫–æ–¥–∏—Ä–æ–≤–∫–æ–π")

    # –°–æ–∑–¥–∞–µ–º —Å–≤–æ–¥–Ω—É—é —Ç–∞–±–ª–∏—Ü—É
    summary_data = []

    for batch_id, data in all_results.items():
        comparison_df = data['comparison_df']
        batch_metrics = metrics['detailed'][batch_id]

        # –û—Å–Ω–æ–≤–Ω—ã–µ –ø–æ–∫–∞–∑–∞—Ç–µ–ª–∏
        final_titer = data['results_df']['P'].iloc[-1]
        peak_xv = data['results_df']['Xv'].max()

        # ML –∫–æ—Ä—Ä–µ–∫—Ü–∏–∏
        ml_correction_mean = 0
        if 'ml_corrections' in data and not data['ml_corrections'].empty:
            ml_correction_mean = data['ml_corrections']['correction'].mean() * 100

        summary_data.append({
            'batch_id': batch_id,
            'final_titer_g_L': round(final_titer, 2),
            'peak_Xv_1e6_per_mL': round(peak_xv, 1),
            'mean_ml_correction_percent': round(ml_correction_mean, 1),
            'mean_r2': round(batch_metrics['_summary']['Mean_R2'], 3),
            'mean_mape': round(batch_metrics['_summary']['Mean_MAPE'], 1)
        })

    summary_df = pd.DataFrame(summary_data)
    summary_csv_path = os.path.join(output_dir, "summary.csv")
    try:
        summary_df.to_csv(summary_csv_path, index=False, encoding='utf-8-sig')
        print(f"‚úÖ –°–≤–æ–¥–Ω–∞—è —Ç–∞–±–ª–∏—Ü–∞ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∞: {summary_csv_path}")
    except Exception as e:
        print(f"‚ö†Ô∏è  –û—à–∏–±–∫–∞ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è CSV: {str(e)}")
        summary_df.to_csv(summary_csv_path, index=False)
        print(f"‚úÖ –°–≤–æ–¥–Ω–∞—è —Ç–∞–±–ª–∏—Ü–∞ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∞ (—Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω–∞—è –∫–æ–¥–∏—Ä–æ–≤–∫–∞)")

    # –í—ã–≤–æ–¥ –≤ –∫–æ–Ω—Å–æ–ª—å
    print(f"\nüìä –°–í–û–î–ù–´–ï –†–ï–ó–£–õ–¨–¢–ê–¢–´:")
    print(summary_df.to_string(index=False))

    return summary_df


if __name__ == "__main__":
    # –ü—Ä–∏–º–µ—Ä –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è
    import argparse

    parser = argparse.ArgumentParser(description='–ì–∏–±—Ä–∏–¥–Ω—ã–π —Å–∏–º—É–ª—è—Ç–æ—Ä CHO')
    parser.add_argument('--batch', type=str, help='–ù–æ–º–µ—Ä –ø–∞—Ä—Ç–∏–∏ (01, 02, ...)')
    parser.add_argument('--all', action='store_true', help='–ó–∞–ø—É—Å—Ç–∏—Ç—å –≤—Å–µ –ø–∞—Ä—Ç–∏–∏')
    parser.add_argument('--no-ml', action='store_true', help='–ë–µ–∑ ML –∫–æ—Ä—Ä–µ–∫—Ü–∏–∏')

    args = parser.parse_args()

    if args.all:
        # –ó–∞–ø—É—Å–∫ –≤—Å–µ—Ö –ø–∞—Ä—Ç–∏–π
        run_all_hybrid_simulations(use_ml_correction=not args.no_ml)
    elif args.batch:
        # –ó–∞–ø—É—Å–∫ –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ–π –ø–∞—Ä—Ç–∏–∏
        csv_path = f"data/raw/batch_CHO{args.batch}.csv"
        meta_path = f"data/meta/batch_CHO{args.batch}.json"
        batch_id = f"CHO{args.batch}"

        run_hybrid_simulation(
            csv_path=csv_path,
            meta_path=meta_path,
            output_path=f"data/hybrid_results/simulation_{batch_id}",
            batch_id=batch_id,
            use_ml_correction=not args.no_ml
        )
    else:
        print("–ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ:")
        print("  --all              –ó–∞–ø—É—Å—Ç–∏—Ç—å –≤—Å–µ –ø–∞—Ä—Ç–∏–∏")
        print("  --batch <–Ω–æ–º–µ—Ä>    –ó–∞–ø—É—Å—Ç–∏—Ç—å –∫–æ–Ω–∫—Ä–µ—Ç–Ω—É—é –ø–∞—Ä—Ç–∏—é")
        print("  --no-ml            –ë–µ–∑ ML –∫–æ—Ä—Ä–µ–∫—Ü–∏–∏")
